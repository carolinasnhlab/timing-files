#This is a template R script file to create timing files. The script will create 1 timing file for each condition for each participant. 

#In order to run this script you will need a folder with data for each participant. 

#Naming convention of the files: The files must follow a naming convention such that the filenames 
#are all the same except they all end with sequential three digit* ID (101) that start with 101 and 
#increase numerically by one. As an example: sub_101; sub_102; etc.

#* This naming convention only works if you have under 1000 participants. 
#* For projects with 1000 or more participants use a 5 digit ID

#The files must contain: 
#a) a column that indicates condition for each row of data
#b) a column that indicates how much time elapsed before the condition occurred (i.e. time onset values), and 
#c) a column that indicates how much time elapsed during the condition (i.e. time duration values).

#Naming conventions for example data and in this template script below
#a) condition = condition
#b) onset values = onset
#c) time duration values = duration
#d) subject IDs = ID
#e) csv. file prefix = sub_

#### Script Set-up ####
rm(list = ls()) 

library(tidyverse)
library(dplyr)

input <- "~/Google Drive/Courses/2020 Courses/Computational Statistics/Final Project/input_test_project/"    
output <- "~/Google Drive/Courses/2020 Courses/Computational Statistics/Final Project/output_test_project/" 
setwd(input)

#Read in files from folder; creates a list of all .csv files in input folder
file_list <- list.files(path=input, pattern="*.csv") # 

# Create empty list for files to go to
onsets<-list()

#read in each .csv file in file_list 
for (i in 1:length(file_list)){
  onsets[[i]]<-read.table(paste(file_list[i], sep=''), sep=',', header=T)
}

# name each element in list
names(onsets)<-file_list

#Below creates a list of the subject IDs (using only the last 3 digits of their ID) below. The loop will cycle 
#through this list,and perform a function on each subject ID. The numbers 5 and 7 need to be changed to the
#character number representing the min and max length of the participant IDs. So for the example data files, 
#sub_102.csv, sub_1 makes up 5 characters, and the total length of sub_102 equals 7 characters. This tells R 
#to extract the part of the file name that represents the full participant ID.

sub_IDs <- unique(substr(names(onsets), 5, 7)) 

#Start of the forloop
#The script below will read in each file for each subject, then pull the onset and duration files for each 
#participant and put them into 4 separate files (1 for each condition). It will also create a column of 1s 
#for the parametric modulator. If you have a fifth condition use copy/paste as needed.

for (subject in sub_IDs) {

#The line below will read in each subjects data. 'read.table' takes at minimum, one arguments (filepath). 
#Here we are specifying the file path for each subject, by taking the generic filepath and pasting in the subject ID 
#from our list (with no spaces). You can add a second, optional argument 'skip' to skip the first row in each txt doc 
#(with start date and time). For example, you can add the 'skip' argument (, skip=1) if the first row of your data is reserved 
#for date/time information. 

  data <- read.csv(paste(input, "sub_",
                         subject, ".csv", sep = ""))

  condition1 <- data %>%
    filter(condition=="1") %>%
    select(onset,duration) %>%
    mutate(pm=1)

  write.table(condition1, paste(output, subject, "_condition1.txt", 
                                sep = ""), row.names=FALSE, col.names = FALSE)
  
  condition2 <- data %>%
    filter(condition=="2") %>%
    select(onset,duration) %>%
    mutate(pm=1)
  
  write.table(condition2, paste(output, subject, "_condition2.txt", 
                                sep = ""), row.names=FALSE, col.names = FALSE)
  condition3 <- data %>%
    filter(condition=="3") %>%
    select(onset,duration) %>%
    mutate(pm=1)
  
  write.table(condition3, paste(output, subject, "_condition3.txt", 
                                sep = ""), row.names=FALSE, col.names = FALSE)
  condition4 <- data %>%
    filter(condition=="4") %>%
    select(onset,duration) %>%
    mutate(pm=1)
  
  write.table(condition4, paste(output, subject, "_condition4.txt", 
                                sep = ""), row.names=FALSE, col.names = FALSE)
}

#####Generating Files when missing data#####

sub_files <- setNames(lapply(sub_IDs, function(x) {
  files <- dir()[startsWith(dir(), paste0("sub_", x))]
}), sub_IDs)

onsets_sub <- lapply(sub_files, function(x) {
  out <- dplyr::bind_rows(onsets[names(onsets) %in% x], .id = "file")
  out
})

onsets_df <- dplyr::bind_rows(onsets_sub, .id = "ID") ##this requires that we have a column with ID #


##Step 2: Get number of times each participant sees each condition and export it to csv

qa <- subset(as.data.frame(with(onsets_df, table(ID,condition)), Freq = 0))


##Step 3: Identify who and what is missing data#####

missing <- qa %>%
  filter(Freq=="0") 

#####Step 4: Creating blank EV for those missing conditions#####

blank<- data.frame(0,0,0)

for (i in 1:nrow(missing)){
  write.table(blank, 
              file = paste0(output, missing$ID[i],
                            "_condition_", missing$condition[i],
                            ".txt"), sep='\t', col.names = FALSE, row.names = FALSE)
}
